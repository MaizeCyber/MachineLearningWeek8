{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Objective\n",
    "\n",
    "The primary objective of the machine learning model is classification. We want to determine which connections a firewall should allow, deny, drop, or \"reset-both.\" Automating the classification of firewall rules is beneficial because many features of network traffic, such as bytes sent, are continuous rather than discrete, making set threshold values difficult to set. In addition, malicious or unwanted traffic likely cannot be identified by just one factor. For example, traffic over a certain port may normally be benign, but high volume could indicate malicious activity. Finally, machine learning can help identify trends and patterns that are too difficult for humans to identify manually, but emerge given enough training data.\n",
    "\n"
   ],
   "id": "822b4fe590a22659"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "The data set contains the following features: Source Port, Destination Port, NAT Source Port, NAT Destination Port, Bytes, Bytes Sent, Bytes Received, Packets, Elapsed Time (sec), pkts_sent, pkts_received, and Class. Only on of the features, Class, is categorical. These are the target values we will use to train the model for classification.\n",
    "\n",
    "To begin train a model for classification, we have to convert the string classes into numbers that sklearn can process. To do this we use sklearn's LabelEncoder to preprocess the classes. We pass the column of the class to the method fit_transform. This creates an object containing our target values converted to integers and ready for training. We can still view the associated strings with by printing \"le.classes_\"."
   ],
   "id": "b3670c6750167d01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Encode the classes\n",
    "y = le.fit_transform(df[classColumn])\n",
    "class_names = le.classes_\n",
    "print('Class labels:', class_names)\n",
    "# Class labels: ['allow' 'deny' 'drop' 'reset-both']"
   ],
   "id": "b15dc637100be0d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Models Explored\n",
    "\n",
    "I used Decision Trees, Random Forest, and Naive Bayes to classify the data. I decided to add Naive Bayes as I intend to use it in my final project and wanted to be familiary with how it functioned.\n",
    "\n",
    "### Decisions Trees\n",
    "\n",
    "#### Hyperparameters\n",
    "My previous work during week five found that using the Gini impurity measure performed better than Entropy. In addition, I attained significantly better accuracy until a depth of five, when accuracy gains started to level off.\n",
    "\n",
    "#### Results\n",
    "\n",
    "METRICS FOR DEPTH 5 AND CRITERION Gini\n",
    "\n",
    "Overall Accuracy: 0.9984\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "| | precision | recall | f1-score | support |\n",
    "|:---|:---:|:---:|:---:|---:|\n",
    "| **allow** | 1.00 | 1.00 | 1.00 | 30063 |\n",
    "| **deny** | 1.00 | 1.00 | 1.00 | 12011 |\n",
    "| **drop** | 1.00 | 1.00 | 1.00 | 10308 |\n",
    "| **reset-both** | 1.00 | 0.23 | 0.37 | 44 |\n",
    "| | | | | |\n",
    "| **accuracy** | | | 1.00 | 52426 |\n",
    "| **macro avg** | 1.00 | 0.81 | 0.84 | 52426 |\n",
    "| **weighted avg** | 1.00 | 1.00 | 1.00 | 52426 |\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "Training Accuracy: 0.9984\n",
    "\n",
    "Test Accuracy:     0.9984\n",
    "\n",
    "The actual depth of the tree is: 5\n",
    "\n",
    "(The maximum allowed depth was: 5)"
   ],
   "id": "332eaa08b3d0cf8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Random Forest\n",
    "#### Hyperparameters\n",
    "I decided to set n_estimators, meaning the number of decision trees in the forest, to 100, which is the default\n",
    "\n",
    "#### Results\n",
    "\n",
    "METRICS FOR RANDOM FOREST MODEL\n",
    "\n",
    "(Estimators: 100, LR: 1.0)\n",
    "\n",
    "Overall Accuracy: 0.9996\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "| | precision | recall | f1-score | support |\n",
    "|:---|:---:|:---:|:---:|---:|\n",
    "| **allow** | 1.00 | 1.00 | 1.00 | 30063 |\n",
    "| **deny** | 1.00 | 1.00 | 1.00 | 12011 |\n",
    "| **drop** | 1.00 | 1.00 | 1.00 | 10308 |\n",
    "| **reset-both** | 1.00 | 0.98 | 0.99 | 44 |\n",
    "| | | | | |\n",
    "| **accuracy** | | | 1.00 | 52426 |\n",
    "| **macro avg** | 1.00 | 0.99 | 1.00 | 52426 |\n",
    "| **weighted avg** | 1.00 | 1.00 | 1.00 | 52426 |\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "Training Accuracy: 0.9998\n",
    "\n",
    "Test Accuracy:     0.9996"
   ],
   "id": "df22376136fd7342"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Complement Naive Bayes\n",
    "#### Hyperparameters\n",
    "I decided to use a variation of Naive Bayes, Complement Naive Bayes, because sklearn suggested it performed better on highly imbalanced dataset. I used the default setting for hyperparameters.\n",
    "\n",
    "#### Results\n",
    "\n",
    "METRICS FOR COMPLEMENT NAIVE BAYES\n",
    "\n",
    "Overall Accuracy: 0.9128\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "| | precision | recall | f1-score | support |\n",
    "|:---|:---:|:---:|:---:|---:|\n",
    "| **allow** | 1.00 | 0.88 | 0.93 | 30063 |\n",
    "| **deny** | 0.98 | 0.93 | 0.96 | 12011 |\n",
    "| **drop** | 0.71 | 1.00 | 0.83 | 10308 |\n",
    "| **reset-both** | 0.00 | 0.00 | 0.00 | 44 |\n",
    "| | | | | |\n",
    "| **accuracy** | | | 0.91 | 52426 |\n",
    "| **macro avg** | 0.67 | 0.70 | 0.68 | 52426 |\n",
    "| **weighted avg** | 0.94 | 0.91 | 0.92 | 52426 |\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "Training Accuracy: 0.9138\n",
    "\n",
    "Test Accuracy:     0.9128\n",
    "\n",
    "\n",
    "\n",
    "Accuracy: 0.9128295120741616\n",
    "\n",
    "F1 Score: 0.908917365026234\n"
   ],
   "id": "1fb449890f57992b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "id": "f67996327deba58a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
